<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Cheung's Blog - 飞雪连天射白鹿，笑书神侠倚碧鸳</title><meta name="author" content="Cheung"><meta name="copyright" content="Cheung"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="个人博客，主要记录有关看论文、学习计算机科学的笔记">
<meta property="og:type" content="website">
<meta property="og:title" content="Cheung&#39;s Blog">
<meta property="og:url" content="http://kevin-zhang-sysu.github.io/index.html">
<meta property="og:site_name" content="Cheung&#39;s Blog">
<meta property="og:description" content="个人博客，主要记录有关看论文、学习计算机科学的笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://kevin-zhang-sysu.github.io/static_img/me.jpg">
<meta property="article:author" content="Cheung">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://kevin-zhang-sysu.github.io/static_img/me.jpg"><link rel="shortcut icon" href="/static_img/me.jpg"><link rel="canonical" href="http://kevin-zhang-sysu.github.io/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?d65eed546e2912533944787b69fa83eb";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-RYGQ5K1B81"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-RYGQ5K1B81');
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Cheung\'s Blog',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2025-01-16 14:32:38'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "/static_img/loading.gif" data-lazy-src="/static_img/me.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/static_img/%E7%A8%BB%E5%9F%8E%E4%BA%9A%E4%B8%81.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Cheung's Blog"><span class="site-name">Cheung's Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Cheung's Blog</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/Kevin-Zhang-SYSU" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/zy_sysu?type=blog" target="_blank" title="CSDN"><i class="fa fa-book-open"></i></a><a class="social-icon" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=2651309292&amp;website=www.oicqzone.com" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="mailto:2651309292.com" target="_blank" title="Email"><i class="fas fa-envelope-open-text"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2025/01/16/Sia/" title="Sia-考虑集群异构性和作业弹性的DL训练系统"><img class="post-bg" src= "/static_img/loading.gif" data-lazy-src="/posts_img/Sia/4.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Sia-考虑集群异构性和作业弹性的DL训练系统"></a></div><div class="recent-post-info"><a class="article-title" href="/2025/01/16/Sia/" title="Sia-考虑集群异构性和作业弹性的DL训练系统">Sia-考虑集群异构性和作业弹性的DL训练系统</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-01-16T06:22:46.000Z" title="发表于 2025-01-16 14:22:46">2025-01-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Paper-Report/">Paper Report</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/DL/">DL</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Train/">Train</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Mlsys/">Mlsys</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Heterogeneity/">Heterogeneity</a></span></div><div class="content">Sia 调度器结合Gavel和Pollux这两篇文章的优势，提出了一种为异构深度学习集群的弹性资源自适应作业提供高效资源分配的方法，解决了现有调度器在异构性和资源适应性上的不足。Sia 使用Bootstrapping + 在线优化的方法，低开销、快速评估作业在不同配置下的性能，接着使用ILP算法进行资源分配，能够在大规模集群中高效扩展，并根据集群负载和作业需求动态调整。Sia 是首个支持混合并行作业弹性扩展的集群调度器。广泛的实验表明，Sia 在多个工作负载环境中显著提高了作业完成效率和资源利用率，并且具有良好的扩展性和公平性，能够支持高达 2000 GPU 的集群。
论文：(SOSP 2023)Sia: Heterogeneity-aware, goodput-optimized ML-cluster scheduling
代码：https://github.com/siasosp23/artifacts
研究背景及内容深度学习模型的训练和推理，对计算资源的要求极为庞大，对于普通企业和用户而言部署的成本巨大，基于此背景，各大企业的深度学习云计算平台应运而生。

用户会将深度学习模型部 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/01/16/Sia_/" title="无题">无题</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-01-16T06:18:08.900Z" title="发表于 2025-01-16 14:18:08">2025-01-16</time></span></div><div class="content">Sia 调度器结合Gavel和Pollux这两篇文章的优势，提出了一种为异构深度学习集群的弹性资源自适应作业提供高效资源分配的方法，解决了现有调度器在异构性和资源适应性上的不足。Sia 使用Bootstrapping + 在线优化的方法，低开销、快速评估作业在不同配置下的性能，接着使用ILP算法进行资源分配，能够在大规模集群中高效扩展，并根据集群负载和作业需求动态调整。Sia 是首个支持混合并行作业弹性扩展的集群调度器。广泛的实验表明，Sia 在多个工作负载环境中显著提高了作业完成效率和资源利用率，并且具有良好的扩展性和公平性，能够支持高达 2000 GPU 的集群。
论文：https://suhasjs.github.io/files/sia-sosp23.pdf
代码：https://github.com/siasosp23/artifacts
研究背景及内容深度学习模型的训练和推理，对计算资源的要求极为庞大，对于普通企业和用户而言部署的成本巨大，基于此背景，各大企业的深度学习云计算平台应运而生。

用户会将深度学习模型部署到云端，进行训练或推理作业，通常会请求一定的计算资源，以保 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/09/19/Alpa/" title="Alpa-自动生成DL/LLM模型并行策略"><img class="post-bg" src= "/static_img/loading.gif" data-lazy-src="/posts_img/Alpa/cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Alpa-自动生成DL/LLM模型并行策略"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/09/19/Alpa/" title="Alpa-自动生成DL/LLM模型并行策略">Alpa-自动生成DL/LLM模型并行策略</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-18T16:41:49.000Z" title="发表于 2024-09-19 00:41:49">2024-09-19</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Paper-Report/">Paper Report</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LLM/">LLM</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/DL/">DL</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Train/">Train</a></span></div><div class="content">只要输入DL模型 computation graph 和 device cluster，Alpa 通过生成统一数据、运算和流水线并行性的执行计划，在可接受的时间内自动化了大型深度学习（DL）模型的模型并行训练。
现有的模型并行训练系统要么要求用户手动创建并行化计划，要么从有限的模型并行配置空间中自动生成一个。它们不足以在分布式计算设备上扩展复杂的DL模型。Alpa通过将并行性视为两个层次来分配大型DL模型的训练：**运算内并行性(inter-operator)和运算间并行性(intra-operator)**。
基于此，Alpa为大规模模型并行执行计划构建了一个新的层次空间。Alpa设计了许多编译过程，以在每个并行级别自动导出高效的并行执行计划。Alpa实现了高效的运行时，以协调分布式计算设备上的两级并行执行。评估表明，Alpa生成的并行化计划与手动调优的模型并行训练系统相匹配或优于后者，即使在它们设计的模型上也是如此。与专用系统不同，Alpa还可以推广到具有异构架构的模型和没有手动设计计划的模型。
论文：(OSDI 2022)Alpa: Automating Inter- and I ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/09/14/vLLM/" title="vLLM-高效管理内存的LLM推理系统"><img class="post-bg" src= "/static_img/loading.gif" data-lazy-src="/posts_img/vLLM/6.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="vLLM-高效管理内存的LLM推理系统"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/09/14/vLLM/" title="vLLM-高效管理内存的LLM推理系统">vLLM-高效管理内存的LLM推理系统</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-14T15:02:45.000Z" title="发表于 2024-09-14 23:02:45">2024-09-14</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Paper-Report/">Paper Report</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LLM/">LLM</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Inference/">Inference</a></span></div><div class="content">LLM在处理大量请求时面临内存使用效率低下的问题，每个请求需占用大量动态变化的内存，导致浪费并限制处理能力。本文提出了PagedAttention算法，受操作系统虚拟内存分页技术启发，开发了vLLM服务系统。vLLM通过灵活共享内存，实现几乎零内存浪费，显著降低了内存需求。测试表明，vLLM处理吞吐量比FasterTransformer和Orca提高2到4倍，且延迟保持相同，尤其在处理长文本、大模型和复杂解码时表现突出。
论文：(SOSP 2023)代码：https://github.com/vllm-project/vllm文章参考自：https://mp.weixin.qq.com/s/whsGK2gfVrIDNXTtxUUSOw
介绍许多云服务公司正在争相提供LLM应用，但运行这些应用的成本非常高，需要大量的硬件加速器如GPU。据估计，处理一次大语言模型的请求，成本是传统关键词查询的 10 倍。由于成本如此之高，提升大语言模型的处理效率，从而降低每次请求的费用，变得越来越重要。
大语言模型（LLM）的核心是一个自回归的Transformer模型。这个模型根据输入的提示和之前生成的 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/09/14/Orca/" title="Orca-大模型推理系统开山之作"><img class="post-bg" src= "/static_img/loading.gif" data-lazy-src="/posts_img/Orca/cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Orca-大模型推理系统开山之作"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/09/14/Orca/" title="Orca-大模型推理系统开山之作">Orca-大模型推理系统开山之作</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-14T04:24:22.000Z" title="发表于 2024-09-14 12:24:22">2024-09-14</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Paper-Report/">Paper Report</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LLM/">LLM</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Inference/">Inference</a></span></div><div class="content">本文提出了一种新的分布式服务系统 ORCA，针对大规模 Transformer 模型的自回归生成任务，解决了现有推理服务系统在多迭代特性任务上表现不佳的问题。ORCA 通过引入 迭代级调度 和 选择性批处理 两项技术，实现了更灵活高效的调度。实验结果表明，在处理 GPT-3 175B 模型时，ORCA 在保持相同延迟的情况下，吞吐量较 NVIDIA FasterTransformer 提升了 36.9 倍。
论文：(OSDI 2022)ORCA: A Distributed Serving System for Transformer-Based Generative Models
引言本文讨论了在服务大规模 Transformer 模型时面临的挑战，特别是用于生成任务的模型，如语言生成、代码生成等。典型的例子包括 GPT-3 这样的模型。随着对模型需求的不断增长，低延迟和高吞吐量成为推理系统的目标，早期通过使用如Triton和FasterTransformer的组合来部署服务，Triton主要负责将多个客户端请求分组到一个批中，而FasterTransformer作为模型推理进行优化 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/09/13/MOE-Intro/" title="MOE基础介绍"><img class="post-bg" src= "/static_img/loading.gif" data-lazy-src="/posts_img/MOE-Intro/1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MOE基础介绍"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/09/13/MOE-Intro/" title="MOE基础介绍">MOE基础介绍</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-13T08:53:07.000Z" title="发表于 2024-09-13 16:53:07">2024-09-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Intro/">Intro</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LLM/">LLM</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/MOE/">MOE</a></span></div><div class="content">MOE重要性：坊间一直流传GPT-4是MoE模型本文主要参考自：https://huggingface.co/blog/zh/moe
什么是MOE基于 Transformer 架构的模型，混合专家模型主要由两个关键部分组成:
● 稀疏 MoE 层: 这些层代替了传统 Transformer 模型中的前馈网络 (FFN) 层。MoE 层包含若干“专家”(例如 8 个)，每个专家本身是一个独立的神经网络。在实际应用中，这些专家通常是前馈网络 (FFN)，但它们也可以是更复杂的网络结构，甚至可以是 MoE 层本身，从而形成层级式的 MoE 结构。
● 门控网络或路由: 这个部分用于决定哪些令牌 (token) 被发送到哪个专家。例如，在下图中，“More”这个令牌可能被发送到第二个专家，而“Parameters”这个令牌被发送到第一个专家。有时，一个令牌甚至可以被发送到多个专家。令牌的路由方式是 MoE 使用中的一个关键点，因为路由器由学习的参数组成，并且与网络的其他部分一同进行预训练。


  Outrageously Large Neural Network 论文中的 MoE layer ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/09/12/MOE-Offloading/" title="MOE利用Offload进行高效推理"><img class="post-bg" src= "/static_img/loading.gif" data-lazy-src="/posts_img/MOE-Offloading/1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MOE利用Offload进行高效推理"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/09/12/MOE-Offloading/" title="MOE利用Offload进行高效推理">MOE利用Offload进行高效推理</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-12T15:22:07.000Z" title="发表于 2024-09-12 23:22:07">2024-09-12</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Paper-Report/">Paper Report</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LLM/">LLM</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/MOE/">MOE</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Inference/">Inference</a></span></div><div class="content">这篇文章提出了如何在资源受限的消费级硬件上高效地运行稀疏专家混合（MoE）语言模型的方法。将Mixtral-8x7B这个需要100G以上算力才能部署的模型在12G显存+11G内存的组合下跑出来。论文：https://arxiv.org/abs/2312.17238Colab代码：https://colab.research.google.com/drive/1ZkC0k487oBEF19R8_9nq2MSHFyQ6OspG?usp=drive_link
引言与背景论文的引言部分介绍了大规模预训练语言模型（LLMs）在自然语言处理领域的重要性。这些模型如GPT-3、GPT-4以及其他开放访问的LLMs（如LLaMA、Falcon、BLOOM等）推动了语言技术的迅猛发展。然而，LLMs 的庞大参数量使得它们的推理成本极高，通常需要高端的GPU设备才能运行，限制了它们在普通硬件上的使用。为了缓解这个问题，稀疏的专家混合（MoE）模型被提出。MoE通过只激活模型中的一部分“专家”来计算每个输入，从而提高了计算效率。然而，MoE模型的规模依然庞大，尤其是在需要多GPU的环境下。因此，如何在消费级 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/09/12/hello-world/" title="Hello World">Hello World</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-12T07:33:14.000Z" title="发表于 2024-09-12 15:33:14">2024-09-12</time></span></div><div class="content">Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.
博客搭建参考文章：【Hexo】Hexo搭建Butterfly主题并快速美化_hexo butterfly-CSDN博客
Quick StartCreate a new post$ hexo new &quot;My New Post&quot;

More info: Writing
Run server$ hexo server

More info: Server
Generate static files$ hexo generate

More info: Generating
Deploy to remote sites$ hexo deploy

More info: Deployment
</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "/static_img/loading.gif" data-lazy-src="/static_img/me.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Cheung</div><div class="author-info__description">个人博客，主要记录有关看论文、学习计算机科学的笔记</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Kevin-Zhang-SYSU"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Kevin-Zhang-SYSU" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/zy_sysu?type=blog" target="_blank" title="CSDN"><i class="fa fa-book-open"></i></a><a class="social-icon" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=2651309292&amp;website=www.oicqzone.com" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="mailto:2651309292.com" target="_blank" title="Email"><i class="fas fa-envelope-open-text"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">任重道远，毋忘奋斗</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/01/16/Sia/" title="Sia-考虑集群异构性和作业弹性的DL训练系统"><img src= "/static_img/loading.gif" data-lazy-src="/posts_img/Sia/4.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Sia-考虑集群异构性和作业弹性的DL训练系统"/></a><div class="content"><a class="title" href="/2025/01/16/Sia/" title="Sia-考虑集群异构性和作业弹性的DL训练系统">Sia-考虑集群异构性和作业弹性的DL训练系统</a><time datetime="2025-01-16T06:22:46.000Z" title="发表于 2025-01-16 14:22:46">2025-01-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/16/Sia_/" title="无题">无题</a><time datetime="2025-01-16T06:18:08.900Z" title="发表于 2025-01-16 14:18:08">2025-01-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/19/Alpa/" title="Alpa-自动生成DL/LLM模型并行策略"><img src= "/static_img/loading.gif" data-lazy-src="/posts_img/Alpa/cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Alpa-自动生成DL/LLM模型并行策略"/></a><div class="content"><a class="title" href="/2024/09/19/Alpa/" title="Alpa-自动生成DL/LLM模型并行策略">Alpa-自动生成DL/LLM模型并行策略</a><time datetime="2024-09-18T16:41:49.000Z" title="发表于 2024-09-19 00:41:49">2024-09-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/14/vLLM/" title="vLLM-高效管理内存的LLM推理系统"><img src= "/static_img/loading.gif" data-lazy-src="/posts_img/vLLM/6.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="vLLM-高效管理内存的LLM推理系统"/></a><div class="content"><a class="title" href="/2024/09/14/vLLM/" title="vLLM-高效管理内存的LLM推理系统">vLLM-高效管理内存的LLM推理系统</a><time datetime="2024-09-14T15:02:45.000Z" title="发表于 2024-09-14 23:02:45">2024-09-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/14/Orca/" title="Orca-大模型推理系统开山之作"><img src= "/static_img/loading.gif" data-lazy-src="/posts_img/Orca/cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Orca-大模型推理系统开山之作"/></a><div class="content"><a class="title" href="/2024/09/14/Orca/" title="Orca-大模型推理系统开山之作">Orca-大模型推理系统开山之作</a><time datetime="2024-09-14T04:24:22.000Z" title="发表于 2024-09-14 12:24:22">2024-09-14</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Intro/"><span class="card-category-list-name">Intro</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Paper-Report/"><span class="card-category-list-name">Paper Report</span><span class="card-category-list-count">5</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/Inference/" style="font-size: 1.37em; color: #99a4b2">Inference</a> <a href="/tags/DL/" style="font-size: 1.23em; color: #999ea6">DL</a> <a href="/tags/LLM/" style="font-size: 1.5em; color: #99a9bf">LLM</a> <a href="/tags/Heterogeneity/" style="font-size: 1.1em; color: #999">Heterogeneity</a> <a href="/tags/MOE/" style="font-size: 1.23em; color: #999ea6">MOE</a> <a href="/tags/Train/" style="font-size: 1.23em; color: #999ea6">Train</a> <a href="/tags/Mlsys/" style="font-size: 1.1em; color: #999">Mlsys</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/01/"><span class="card-archive-list-date">一月 2025</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><span class="card-archive-list-count">6</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">8</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2024-09-10T16:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">16.2k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-01-16T06:32:38.179Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Cheung</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.8/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>window.typedJSFn = {
  init: (str) => {
    window.typed = new Typed('#subtitle', Object.assign({
      strings: str,
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50,
    }, null))
  },
  run: (subtitleType) => {
    if (true) {
      if (typeof Typed === 'function') {
        subtitleType()
      } else {
        getScript('https://cdn.jsdelivr.net/npm/typed.js@2.1.0/dist/typed.umd.min.js').then(subtitleType)
      }
    } else {
      subtitleType()
    }
  }
}
</script><script>function subtitleType () {
  getScript('https://sdk.jinrishici.com/v2/browser/jinrishici.js').then(() => {
    jinrishici.load(result =>{
      if (true) {
        const sub = ["飞雪连天射白鹿，笑书神侠倚碧鸳"]
        const content = result.data.content
        sub.unshift(content)
        typedJSFn.init(sub)
      } else {
        document.getElementById('subtitle').textContent = result.data.content
      }
    })
  })
}
typedJSFn.run(subtitleType)
</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>