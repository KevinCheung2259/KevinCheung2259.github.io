---
layout: fast
title: EP03-vLLMæºç è®²è§£ç›´æ’­ç¬”è®°-PDåˆ†ç¦»
date: 2025-03-30 19:22:07
summary: 
cover: posts_img/vLLM/cover.png
categories: 
  - Note
tags: 
  - vLLM
  - LLM
  - Inference
---

# [FIXME][EP03] vLLM æºç è®²è§£ç›´æ’­ç¬”è®°

## EP03: PDåˆ†ç¦»

ç›´æ’­å›çœ‹é“¾æ¥ï¼šhttps://www.youtube.com/watch?v=ih6fcJnhoJI

ç‰¹åˆ«é¸£è°¢ï¼šæœˆçƒå¤§å”ï¼ŒCheng Yihua å¤§ä½¬å¸¦æ¥çš„ç²¾å½©è®²è§£

### ğŸ“Œ 1. ä¸Šå‘¨å›é¡¾ï¼ˆåˆ†å¸ƒå¼é€šä¿¡ä¸å¹¶è¡Œç­–ç•¥ï¼‰

- TPï¼Œall_gather
    - Linear M x N x K -> M x K
    - M * N', N' * K -> M * K
    åœ¨MHAä¸­ï¼Œæ¯ä¸ªå¤´è¢«å‡åŒ€åœ°åˆ†åœ¨ä¸åŒçš„workerä¸Šï¼Œåœ¨è¿›å…¥ä¹‹åçš„çº¿æ€§å±‚å‰è¦åšä¸€æ¬¡all_gatherï¼ˆè¿™é‡Œä¸ç†è§£çš„å¯ä»¥çœ‹çœ‹-lmå¼ é‡å¹¶è¡Œçš„æ–¹æ³•ï¼‰
    - "vllm\model_executor\models\llama.py"
    ```python
    # llamaå‰å‘ä¼ æ’­çš„ä»£ç 
    def forward(
        self,
        positions: torch.Tensor,
        hidden_states: torch.Tensor,
    ) -> torch.Tensor:
        qkv, _ = self.qkv_proj(hidden_states)
        q, k, v = qkv.split([self.q_size, self.kv_size, self.kv_size], dim=-1)
        q, k = self.rotary_emb(positions, q, k)
        attn_output = self.attn(q, k, v)
        output, _ = self.o_proj(attn_output)
        return output
    ```

### âš¡ 2. PDåˆ†ç¦»

- ä»€ä¹ˆæ˜¯PDåˆ†ç¦»ï¼ˆPrefillå’ŒDecodeï¼‰
    - prefill: å¤„ç†è¾“å…¥çš„promptï¼Œç”ŸæˆKVCache
    - decode: æ ¹æ®KVCacheè¿ç»­è‡ªå›å½’ç”Ÿæˆä¸€ä¸ªä¸€ä¸ªçš„token
- ä¸ºä»€ä¹ˆè¦PDåˆ†ç¦»
    - prefill: attention N tokens QKVï¼Œä¸åºåˆ—é•¿åº¦nçš„å¹³æ–¹æˆæ­£æ¯”ï¼Œéœ€è¦ç›¸å½“å¤šæ—¶é—´
    - decode: attention N KV, 1Qï¼Œç”Ÿæˆæ–°çš„tokenï¼Œé€Ÿåº¦è¾ƒå¿«
    - æœ€åˆçš„é€»è¾‘ï¼šprefillä¼˜å…ˆ
    - é—®é¢˜ï¼šå½“æ–°çš„ä¸€ä¸ªrequeståˆ°æ¥æ—¶ï¼Œè¿›è¡Œçš„prefillä¼šä½¿å…¶ä»–æ­£åœ¨decodeçš„requeståœä½
    - è§£å†³æ–¹æ³•ï¼š
        - PDåˆ†ç¦»ï¼ˆPD disaggregationï¼‰
            - æŒ‘æˆ˜æ˜¯Pï¼ŒDçš„æ•°é‡
        - åˆ†å—é¢„å¡«å……ï¼ˆchunked prefillï¼‰ï¼Œå·²åœ¨vllm v1ç‰ˆæœ¬ä¸­é»˜è®¤ä½¿ç”¨
            - æŒ‘æˆ˜æ˜¯chunked_sizeçš„è®¾ç½®ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªprefillå’Œdecodeä¸­çš„trade-off
- PDåˆ†ç¦»çš„å…³é”®é—®é¢˜
    - æ€ä¹ˆä¼ è¾“KVCache
        - ä¸¤ç§æ¨¡å¼ï¼špoolingæ¨¡å¼ï¼ŒP2Pæ¨¡å¼
        - LMCacheéƒ½æ”¯æŒä¸Šé¢ä¸¤ç§æ¨¡å¼ï¼ŒMooncake(pooling)ï¼ŒNIXL(p2p)
    - æ€ä¹ˆä»vllmæå–ï¼ˆæ³¨å…¥ï¼‰KVCache
        - connector API
            - åœ¨model_runnerä¸­è¢«è°ƒç”¨ï¼Œ"vllm\worker\model_runner.py"
            - åœ¨æ¨¡å‹forwardå‰ï¼šå°è¯•æ¥æ”¶KVCacheå¹¶æ³¨å…¥åˆ°åˆ°vllmçš„pages memoryä¸­
            - æ¨¡å‹æ‰§è¡Œ
            - åœ¨æ¨¡å‹forwardåï¼Œå°†KVCacheä»pages memoryä¸­å¹¶å°†å®ƒå‘é€å‡ºå»
              ![](posts_img/vLLM-EP03/1743330247803.png)
                - ä¸¤ä¸ªå‡½æ•°çš„è¯¦ç»†è®¾è®¡åœ¨"vllm\distributed\kv_transfer\kv_transfer_agent.py"ä¸­
                ```python
                # æœ¬è´¨ä¸Šæ˜¯æ ¹æ®model inputè®¡ç®—å‡ºKVCacheæ”¾åœ¨page memoryä¸­çš„ä»€ä¹ˆåœ°æ–¹
                def recv_kv_caches_and_hidden_states(
                    self, model_executable: torch.nn.Module,
                    model_input: "ModelInputForGPUWithSamplingMetadata",
                    kv_caches: List[torch.Tensor]
                ) -> Tuple[Union[torch.Tensor, IntermediateTensors], bool,
                        "ModelInputForGPUWithSamplingMetadata"]:
              
                    return self.connector.recv_kv_caches_and_hidden_states(
                        model_executable, model_input, kv_caches)
                ```
                è¿™é‡Œä¸æ‡‚çš„å¯ä»¥å»çœ‹"vllm\distributed\kv_transfer\kv_connector\simple_connector.py"
    - ä»€ä¹ˆæ—¶å€™å°†requestä»P nodeä¼ è¾“åˆ°D node
        - å…ˆPåDï¼ˆproduction stackï¼‰
        - å…ˆDåPï¼ˆD nodeæ”¶åˆ°åå…ˆæ£€æŸ¥æ˜¯å¦æœ‰KVCacheï¼Œæ²¡æœ‰çš„è¯å†è½¬ç»™P nodeå»åšï¼Œè¿™ä¸ªæ€è·¯ä¸»è¦è€ƒè™‘çš„æ˜¯TTFTï¼‰


